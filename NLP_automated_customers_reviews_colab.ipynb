{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT4O25ylbFHI"
      },
      "source": [
        "# Project | NLP Automated Customers Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrizOlBbFHL"
      },
      "source": [
        "The goal of this project is to automate the processing of customer reviews by comparing traditional machine learning (ML) methods with a deep learning approach (transformers). Additionally, the project aims to use Generative AI to summarize reviews based on ratings and product categories and to create a visualization dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knr2GHr2bFHL"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i3tizw7DbFHM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import spacy\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N77jdaFHbFHN"
      },
      "source": [
        "## Load & Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dbHMciysbFHO",
        "outputId": "054f2676-5943-4e48-cfae-7a0696af48ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3edc2adaa3b4>:9: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(data_path,\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data_path = \"1429_1.csv\"\n",
        "\n",
        "# df = pd.read_csv(data_path)\n",
        "\n",
        "# Colab\n",
        "df = pd.read_csv(data_path,\n",
        "                 # error_bad_lines=False,\n",
        "                 #quoting=3,\n",
        "                 #engine=\"python\",\n",
        "                 #on_bad_lines='warn'\n",
        "                 )\n",
        "\n",
        "#  Relevant columns\n",
        "# 'reviews.text', 'reviews.title', 'reviews.rating'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is1EW_a5bFHP"
      },
      "source": [
        "### EDA on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VuAWO0FFbFHP",
        "outputId": "c8bb17cb-adb4-4b22-8afc-0692766c5c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sentence Length: 30.40 words\n",
            "Max Length: 1858.00 words\n",
            "Min Length: 1.00 words\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate sentence lengths (split by spaces)\n",
        "sentence_lengths = df['reviews.text'].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "# Compute the average sentence length\n",
        "avg_length = sentence_lengths.mean()\n",
        "max_length = sentence_lengths.max()\n",
        "min_length = sentence_lengths.min()\n",
        "\n",
        "print(f\"Average Sentence Length: {avg_length:.2f} words\")\n",
        "print(f\"Max Length: {max_length:.2f} words\")\n",
        "print(f\"Min Length: {min_length:.2f} words\")\n",
        "\n",
        "\n",
        "# Generate a boxplot for sentence lengths\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(sentence_lengths, vert=False, patch_artist=True, boxprops=dict(facecolor='skyblue', color='black'))\n",
        "plt.xlabel('Sentence Length (Words)')\n",
        "plt.title('Boxplot of Sentence Lengths')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "MAX_SENTENCE_LENGTH = 500  # few sentences longer than 500\n",
        "\n",
        "def truncate_sentence(sentence):\n",
        "    words = sentence.split()  # Split sentence into words\n",
        "    return \" \".join(words[:MAX_SENTENCE_LENGTH])  # Keep only first N words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "szx1GDcibFHP",
        "outputId": "0d989484-20a9-44e1-df1b-8569588a7639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.3.8)\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "!python -m spacy download en_core_web_lg\n",
        "import unidecode\n",
        "import spacy\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# Start timer for execution tracking\n",
        "start_time = time.time()\n",
        "\n",
        "# Log: Start of preprocessing\n",
        "logging.info(\"Starting data preprocessing...\")\n",
        "\n",
        "# Map ratings to sentiment labels\n",
        "# # 1,2,3 -> 'NEGATIVE'\n",
        "# 4 -> 'NEUTRAL'\n",
        "# 5 -> 'POSITIVE'\n",
        "\n",
        "df['sentiment'] = df['reviews.rating'].map({\n",
        "    1: 'NEGATIVE',\n",
        "    2: 'NEGATIVE',\n",
        "    3: 'NEGATIVE',\n",
        "    4: 'NEUTRAL',\n",
        "    5: 'POSITIVE'\n",
        "})\n",
        "\n",
        "\n",
        "# Ensure all text values are strings before applying unidecode\n",
        "logging.info(\"Converting all text values to string format...\")\n",
        "df['reviews.text'] = df['reviews.text'].astype(str).apply(unidecode.unidecode)\n",
        "\n",
        "\n",
        "# Log: Loading NLP Model\n",
        "logging.info(\"Loading spacy model: en_core_web_lg\")\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # process the Text with spacy\n",
        "    doc = nlp(text.lower())\n",
        "    # Filter and Lemmatize Tokens\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Log: Applying text preprocessing\n",
        "logging.info(\"Applying text preprocessing to all reviews...\")\n",
        "df['clean_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Log: Time taken\n",
        "end_time = time.time()\n",
        "logging.info(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYTWxQWCbFHQ"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NWHlClIVbFHQ",
        "outputId": "06b8486c-e6f7-40a2-aeaf-76ce8eb577a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8746bbe65c09>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Apply and explode (create multiple rows per sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_long_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mdf_exploded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'split_clean_text'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Each sentence in a new row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8746bbe65c09>\u001b[0m in \u001b[0;36msplit_long_sentences\u001b[0;34m(text, max_length)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Function to split sentences and explode into multiple rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_long_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Split into sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Keep reasonable length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# Log: Start of preprocessing\n",
        "logging.info(\"Starting data preprocessing and train-test split...\")\n",
        "\n",
        "# Define X (features) and y (target labels)\n",
        "X = df[\"clean_text\"]  # Features (processed text)\n",
        "y = df[\"sentiment\"]   # Target labels (POSITIVE, NEUTRAL, NEGATIVE)\n",
        "\n",
        "# Log: Checking for NaN values\n",
        "initial_size = len(df)\n",
        "nan_count = df[['clean_text', 'sentiment']].isna().sum().sum()\n",
        "logging.info(f\"Found {nan_count} missing values. Removing them...\")\n",
        "\n",
        "# Drop rows with NaN values in critical columns\n",
        "df_clean = df.dropna(subset=[\"clean_text\", \"sentiment\"])\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Function to split sentences and explode into multiple rows\n",
        "def split_long_sentences(text, max_length=500):\n",
        "    sentences = sent_tokenize(text)  # Split into sentences\n",
        "    return [s for s in sentences if len(s.split()) <= max_length]  # Keep reasonable length\n",
        "\n",
        "# Apply and explode (create multiple rows per sentence)\n",
        "df['split_clean_text'] = df['clean_text'].apply(split_long_sentences)\n",
        "df_exploded = df.explode('split_clean_text')  # Each sentence in a new row\n",
        "\n",
        "# Log: Data size after cleaning\n",
        "final_size = len(df_clean)\n",
        "logging.info(f\"Data cleaned: {initial_size - final_size} rows removed. Remaining rows: {final_size}\")\n",
        "\n",
        "# Update X and y with cleaned data\n",
        "X = df_clean[\"clean_text\"]\n",
        "y = df_clean[\"sentiment\"]\n",
        "\n",
        "# Log: Splitting dataset\n",
        "logging.info(\"Splitting data into training (80%) and test (20%) sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Log: Summary of dataset split\n",
        "logging.info(f\"Training set size: {len(X_train)} samples\")\n",
        "logging.info(f\"Test set size: {len(X_test)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWgdW0bnbFHR"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#  apply TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)  # Fit only on training data\n",
        "X_test_tfidf = vectorizer.transform(X_test)  # Transform test data using the same vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slzFHWT4bFHR"
      },
      "source": [
        "## Traditional ML model Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSNYn4qmbFHR",
        "outputId": "a84401a0-2e6d-4b36-9466-8ea9ad0b86a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-30 15:41:21,883 - INFO - Training Logistic Regression model...\n",
            "2025-01-30 15:41:23,022 - INFO - Model Accuracy: 0.72\n",
            "2025-01-30 15:41:23,134 - INFO - \n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.64      0.25      0.36       462\n",
            "     NEUTRAL       0.50      0.22      0.30      1708\n",
            "    POSITIVE       0.75      0.94      0.84      4756\n",
            "\n",
            "    accuracy                           0.72      6926\n",
            "   macro avg       0.63      0.47      0.50      6926\n",
            "weighted avg       0.68      0.72      0.67      6926\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Train Logistic Regression model\n",
        "logging.info(\"Training Logistic Regression model...\")\n",
        "model = LogisticRegression(max_iter=500)  # Increase iterations for convergence\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "logging.info(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "logging.info(\"\\nClassification Report:\\n\" + report)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"]\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrqnnL9rbFHS"
      },
      "source": [
        "Paola: Podemos poner par de los demas algoritmos y hacer hyperparameter tuning.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAbN2CWGbFHS"
      },
      "source": [
        "# Transformer approach\n",
        "\n",
        "'bert-base-multilingual-uncased-sentiment'\n",
        "https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
        "\n",
        "This is a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish, and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5).\n",
        "\n",
        "This model is intended for direct use as a sentiment analysis model for product reviews in any of the six languages above or for further finetuning on related sentiment analysis tasks.\n",
        "\n",
        "\n",
        "NOTA: ESTO SE COGE UN MONTON DE TIEMPO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npvThGn5bFHS",
        "outputId": "b0cd57a4-906c-43fc-f001-a8e77e0c4e74"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_map[predicted_class], probabilities_dict\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# trying it out on the data. \u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
            "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[20], line 41\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_map[predicted_class], probabilities_dict\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# trying it out on the data. \u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
            "Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36mpredict_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     12\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get model predictions\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     16\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert logits to prob\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1665\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1665\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1677\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1679\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:524\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    516\u001b[0m         hidden_states,\n\u001b[0;32m    517\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m         output_attentions,\n\u001b[0;32m    523\u001b[0m     )\n\u001b[1;32m--> 524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:466\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    468\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Dan\\Desktop\\GitHub\\Ironhack\\project-nlp-automated-customer-reviews\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Convert logits to prob\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the predicted label (highest probability)\n",
        "    predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    # Map the predicted class to a sentiment\n",
        "    sentiment_map = {\n",
        "        0: \"NEGATIVE\",\n",
        "        1: \"NEGATIVE\",\n",
        "        2: \"NEUTRAL\",\n",
        "        3: \"POSITIVE\",\n",
        "        4: \"POSITIVE\",\n",
        "    }\n",
        "\n",
        "    # Convert probabilities to a dictionary\n",
        "    probabilities_dict = {\n",
        "        sentiment_map[i]: round(float(probs[0, i]) * 100, 2) for i in range(len(sentiment_map))\n",
        "    }\n",
        "    # Log the function output\n",
        "    logging.info(f\"Text: {text}\")\n",
        "    logging.info(f\"Predicted Sentiment: {sentiment_map[predicted_class]}\")\n",
        "    logging.info(f\"Probabilities: {probabilities_dict}\")\n",
        "\n",
        "    return sentiment_map[predicted_class], probabilities_dict\n",
        "\n",
        "# trying it out on the data.\n",
        "df[\"pretrained_sentiment\"] = df[\"clean_text\"].apply(lambda x: predict_sentiment(x)[0])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsdU4SnxbFHS"
      },
      "source": [
        "## Fine-Tuning - TO DO\n",
        "\n",
        "Paola: Me quede hasta aqui, en mi compu del trabajo no esta pa hacer fine tuning so sigo en casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEHijK9qbFHS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}