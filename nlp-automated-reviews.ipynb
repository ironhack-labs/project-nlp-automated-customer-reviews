{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haPC5_a-V_Yc",
        "outputId": "b056f595-e648-4202-a69c-4b1bb5228c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20383 entries, 0 to 20382\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    20383 non-null  object \n",
            " 1   name                  20383 non-null  object \n",
            " 2   asins                 20381 non-null  object \n",
            " 3   brand                 20383 non-null  object \n",
            " 4   categories            20383 non-null  object \n",
            " 5   keys                  20383 non-null  object \n",
            " 6   manufacturer          20383 non-null  object \n",
            " 7   reviews.date          20370 non-null  object \n",
            " 8   reviews.dateAdded     18691 non-null  object \n",
            " 9   reviews.dateSeen      20383 non-null  object \n",
            " 10  reviews.didPurchase   1 non-null      object \n",
            " 11  reviews.doRecommend   19939 non-null  object \n",
            " 12  reviews.id            1 non-null      float64\n",
            " 13  reviews.numHelpful    19953 non-null  float64\n",
            " 14  reviews.rating        20355 non-null  float64\n",
            " 15  reviews.sourceURLs    20383 non-null  object \n",
            " 16  reviews.text          20382 non-null  object \n",
            " 17  reviews.title         20381 non-null  object \n",
            " 18  reviews.userCity      0 non-null      float64\n",
            " 19  reviews.userProvince  0 non-null      float64\n",
            " 20  reviews.username      20377 non-null  object \n",
            "dtypes: float64(5), object(16)\n",
            "memory usage: 3.3+ MB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "id                          0\n",
            "name                        0\n",
            "asins                       2\n",
            "brand                       0\n",
            "categories                  0\n",
            "keys                        0\n",
            "manufacturer                0\n",
            "reviews.date               13\n",
            "reviews.dateAdded        1692\n",
            "reviews.dateSeen            0\n",
            "reviews.didPurchase     20382\n",
            "reviews.doRecommend       444\n",
            "reviews.id              20382\n",
            "reviews.numHelpful        430\n",
            "reviews.rating             28\n",
            "reviews.sourceURLs          0\n",
            "reviews.text                1\n",
            "reviews.title               2\n",
            "reviews.userCity        20383\n",
            "reviews.userProvince    20383\n",
            "reviews.username            6\n",
            "dtype: int64\n",
            "\n",
            "First few rows of the dataset:\n",
            "                     id                                               name  \\\n",
            "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "\n",
            "        asins   brand                                         categories  \\\n",
            "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "\n",
            "                                                keys manufacturer  \\\n",
            "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "\n",
            "               reviews.date     reviews.dateAdded  \\\n",
            "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "\n",
            "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
            "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "\n",
            "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
            "0        NaN                 0.0             5.0   \n",
            "1        NaN                 0.0             5.0   \n",
            "2        NaN                 0.0             5.0   \n",
            "3        NaN                 0.0             4.0   \n",
            "4        NaN                 0.0             5.0   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  This product so far has not disappointed. My c...   \n",
            "1  great for beginner or experienced person. Boug...   \n",
            "2  Inexpensive tablet for him to use and learn on...   \n",
            "3  I've had my Fire HD 8 two weeks now and I love...   \n",
            "4  I bought this for my grand daughter when she c...   \n",
            "\n",
            "                             reviews.title reviews.userCity  \\\n",
            "0                                   Kindle              NaN   \n",
            "1                                very fast              NaN   \n",
            "2  Beginner tablet for our 9 year old son.              NaN   \n",
            "3                                  Good!!!              NaN   \n",
            "4                Fantastic Tablet for kids              NaN   \n",
            "\n",
            "   reviews.userProvince  reviews.username  \n",
            "0                   NaN           Adapter  \n",
            "1                   NaN            truman  \n",
            "2                   NaN             DaveZ  \n",
            "3                   NaN            Shacks  \n",
            "4                   NaN         explore42  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6814050601817735\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.26      0.37       308\n",
            "           1       0.53      0.12      0.20      1129\n",
            "           2       0.69      0.97      0.81      2634\n",
            "\n",
            "    accuracy                           0.68      4071\n",
            "   macro avg       0.62      0.45      0.46      4071\n",
            "weighted avg       0.64      0.68      0.61      4071\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  81   55  172]\n",
            " [  33  141  955]\n",
            " [  11   71 2552]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load Data\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '1429_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Basic Data Exploration\n",
        "print(\"Basic Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Filter Relevant Columns\n",
        "df_filtered = df[['reviews.text', 'reviews.rating']]\n",
        "df_filtered = df_filtered.dropna(subset=['reviews.text', 'reviews.rating'])\n",
        "\n",
        "# Step 4: Download Necessary NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 5: Define Text Cleaning Functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered['reviews.text'].apply(clean_text)\n",
        "\n",
        "# Step 6: Additional Feature Engineering\n",
        "df_filtered['word_count'] = df_filtered['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "df_filtered['avg_word_length'] = df_filtered['cleaned_text'].apply(lambda x: sum(len(word) for word in x.split()) / len(x.split()) if x.split() else 0)\n",
        "\n",
        "# Define a function to categorize ratings into sentiment\n",
        "def categorize_rating(rating):\n",
        "    if rating in [1, 2, 3]:\n",
        "        return 'Negative'\n",
        "    elif rating == 4:\n",
        "        return 'Neutral'\n",
        "    elif rating == 5:\n",
        "        return 'Positive'\n",
        "\n",
        "df_filtered['sentiment'] = df_filtered['reviews.rating'].apply(categorize_rating)\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df_filtered['sentiment_label'] = df_filtered['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Step 7: TF-IDF Feature Engineering\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df_filtered['cleaned_text'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the DataFrame\n",
        "df_filtered = pd.concat([df_filtered.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Prepare the feature set\n",
        "X = df_filtered.drop(columns=['reviews.text', 'reviews.rating', 'sentiment', 'cleaned_text', 'sentiment_label'])\n",
        "y = df_filtered['sentiment_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: SVM Model Training and Evaluation\n",
        "# Initialize and train the SVM model with a linear kernel\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Save the final processed DataFrame\n",
        "df_filtered.to_csv('processed_reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaYnI1KYWQsD",
        "outputId": "3fac277c-2f45-4f5c-a647-9da34a1ddc4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kArRbVEFcDwC",
        "outputId": "1a7063de-b0bf-4e7a-d447-262c327a02a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-ff19c39d0632>:18: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34660 entries, 0 to 34659\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    34660 non-null  object \n",
            " 1   name                  27900 non-null  object \n",
            " 2   asins                 34658 non-null  object \n",
            " 3   brand                 34660 non-null  object \n",
            " 4   categories            34660 non-null  object \n",
            " 5   keys                  34660 non-null  object \n",
            " 6   manufacturer          34660 non-null  object \n",
            " 7   reviews.date          34621 non-null  object \n",
            " 8   reviews.dateAdded     24039 non-null  object \n",
            " 9   reviews.dateSeen      34660 non-null  object \n",
            " 10  reviews.didPurchase   1 non-null      object \n",
            " 11  reviews.doRecommend   34066 non-null  object \n",
            " 12  reviews.id            1 non-null      float64\n",
            " 13  reviews.numHelpful    34131 non-null  float64\n",
            " 14  reviews.rating        34627 non-null  float64\n",
            " 15  reviews.sourceURLs    34660 non-null  object \n",
            " 16  reviews.text          34659 non-null  object \n",
            " 17  reviews.title         34654 non-null  object \n",
            " 18  reviews.userCity      0 non-null      float64\n",
            " 19  reviews.userProvince  0 non-null      float64\n",
            " 20  reviews.username      34653 non-null  object \n",
            "dtypes: float64(5), object(16)\n",
            "memory usage: 5.6+ MB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "id                          0\n",
            "name                     6760\n",
            "asins                       2\n",
            "brand                       0\n",
            "categories                  0\n",
            "keys                        0\n",
            "manufacturer                0\n",
            "reviews.date               39\n",
            "reviews.dateAdded       10621\n",
            "reviews.dateSeen            0\n",
            "reviews.didPurchase     34659\n",
            "reviews.doRecommend       594\n",
            "reviews.id              34659\n",
            "reviews.numHelpful        529\n",
            "reviews.rating             33\n",
            "reviews.sourceURLs          0\n",
            "reviews.text                1\n",
            "reviews.title               6\n",
            "reviews.userCity        34660\n",
            "reviews.userProvince    34660\n",
            "reviews.username            7\n",
            "dtype: int64\n",
            "\n",
            "First few rows of the dataset:\n",
            "                     id                                               name  \\\n",
            "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "\n",
            "        asins   brand                                         categories  \\\n",
            "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "\n",
            "                                                keys manufacturer  \\\n",
            "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "\n",
            "               reviews.date     reviews.dateAdded  \\\n",
            "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "\n",
            "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
            "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "\n",
            "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
            "0        NaN                 0.0             5.0   \n",
            "1        NaN                 0.0             5.0   \n",
            "2        NaN                 0.0             5.0   \n",
            "3        NaN                 0.0             4.0   \n",
            "4        NaN                 0.0             5.0   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  This product so far has not disappointed. My c...   \n",
            "1  great for beginner or experienced person. Boug...   \n",
            "2  Inexpensive tablet for him to use and learn on...   \n",
            "3  I've had my Fire HD 8 two weeks now and I love...   \n",
            "4  I bought this for my grand daughter when she c...   \n",
            "\n",
            "                             reviews.title reviews.userCity  \\\n",
            "0                                   Kindle              NaN   \n",
            "1                                very fast              NaN   \n",
            "2  Beginner tablet for our 9 year old son.              NaN   \n",
            "3                                  Good!!!              NaN   \n",
            "4                Fantastic Tablet for kids              NaN   \n",
            "\n",
            "   reviews.userProvince  reviews.username  \n",
            "0                   NaN           Adapter  \n",
            "1                   NaN            truman  \n",
            "2                   NaN             DaveZ  \n",
            "3                   NaN            Shacks  \n",
            "4                   NaN         explore42  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6724 - loss: 0.8268 - val_accuracy: 0.6952 - val_loss: 0.6879\n",
            "Epoch 2/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.6998 - val_accuracy: 0.7029 - val_loss: 0.6672\n",
            "Epoch 3/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7110 - loss: 0.6716 - val_accuracy: 0.7078 - val_loss: 0.6630\n",
            "Epoch 4/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.6564 - val_accuracy: 0.7108 - val_loss: 0.6565\n",
            "Epoch 5/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6457 - val_accuracy: 0.7107 - val_loss: 0.6597\n",
            "Epoch 6/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.6309 - val_accuracy: 0.7157 - val_loss: 0.6559\n",
            "Epoch 7/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.6424 - val_accuracy: 0.7112 - val_loss: 0.6573\n",
            "Epoch 8/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.6204 - val_accuracy: 0.7130 - val_loss: 0.6575\n",
            "Epoch 9/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.6216 - val_accuracy: 0.7127 - val_loss: 0.6641\n",
            "Epoch 10/10\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.6158 - val_accuracy: 0.7148 - val_loss: 0.6605\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7091 - loss: 0.6697\n",
            "Test Accuracy: 0.7148426175117493\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.33      0.39       435\n",
            "           1       0.55      0.17      0.26      1756\n",
            "           2       0.74      0.95      0.83      4735\n",
            "\n",
            "    accuracy                           0.71      6926\n",
            "   macro avg       0.59      0.48      0.50      6926\n",
            "weighted avg       0.68      0.71      0.66      6926\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 143   78  214]\n",
            " [  90  306 1360]\n",
            " [  63  170 4502]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load Data\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '1429_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Basic Data Exploration\n",
        "print(\"Basic Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Filter Relevant Columns\n",
        "df_filtered = df[['reviews.text', 'reviews.rating']]\n",
        "df_filtered = df_filtered.dropna(subset=['reviews.text', 'reviews.rating'])\n",
        "\n",
        "# Step 4: Download Necessary NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 5: Define Text Cleaning Functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered['reviews.text'].apply(clean_text)\n",
        "\n",
        "# Step 6: Additional Feature Engineering\n",
        "df_filtered['word_count'] = df_filtered['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "df_filtered['avg_word_length'] = df_filtered['cleaned_text'].apply(lambda x: sum(len(word) for word in x.split()) / len(x.split()) if x.split() else 0)\n",
        "\n",
        "# Define a function to categorize ratings into sentiment\n",
        "def categorize_rating(rating):\n",
        "    if rating in [1, 2, 3]:\n",
        "        return 'Negative'\n",
        "    elif rating == 4:\n",
        "        return 'Neutral'\n",
        "    elif rating == 5:\n",
        "        return 'Positive'\n",
        "\n",
        "df_filtered['sentiment'] = df_filtered['reviews.rating'].apply(categorize_rating)\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df_filtered['sentiment_label'] = df_filtered['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Step 7: TF-IDF Feature Engineering\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df_filtered['cleaned_text'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the DataFrame\n",
        "df_filtered = pd.concat([df_filtered.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Prepare the feature set\n",
        "X = df_filtered.drop(columns=['reviews.text', 'reviews.rating', 'sentiment', 'cleaned_text', 'sentiment_label'])\n",
        "y = df_filtered['sentiment_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Neural Network Model Training and Evaluation\n",
        "# Define a simple feedforward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='softmax'))  # Output layer with 3 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Evaluate the model performance\n",
        "classification_rep = classification_report(y_test, y_pred_classes)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Display results\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Save the final processed DataFrame\n",
        "df_filtered.to_csv('processed_reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn4HXE-Ycuh6",
        "outputId": "2d86519a-d3ba-4902-b767-6390accb74e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-efe2d0018085>:19: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34660 entries, 0 to 34659\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    34660 non-null  object \n",
            " 1   name                  27900 non-null  object \n",
            " 2   asins                 34658 non-null  object \n",
            " 3   brand                 34660 non-null  object \n",
            " 4   categories            34660 non-null  object \n",
            " 5   keys                  34660 non-null  object \n",
            " 6   manufacturer          34660 non-null  object \n",
            " 7   reviews.date          34621 non-null  object \n",
            " 8   reviews.dateAdded     24039 non-null  object \n",
            " 9   reviews.dateSeen      34660 non-null  object \n",
            " 10  reviews.didPurchase   1 non-null      object \n",
            " 11  reviews.doRecommend   34066 non-null  object \n",
            " 12  reviews.id            1 non-null      float64\n",
            " 13  reviews.numHelpful    34131 non-null  float64\n",
            " 14  reviews.rating        34627 non-null  float64\n",
            " 15  reviews.sourceURLs    34660 non-null  object \n",
            " 16  reviews.text          34659 non-null  object \n",
            " 17  reviews.title         34654 non-null  object \n",
            " 18  reviews.userCity      0 non-null      float64\n",
            " 19  reviews.userProvince  0 non-null      float64\n",
            " 20  reviews.username      34653 non-null  object \n",
            "dtypes: float64(5), object(16)\n",
            "memory usage: 5.6+ MB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "id                          0\n",
            "name                     6760\n",
            "asins                       2\n",
            "brand                       0\n",
            "categories                  0\n",
            "keys                        0\n",
            "manufacturer                0\n",
            "reviews.date               39\n",
            "reviews.dateAdded       10621\n",
            "reviews.dateSeen            0\n",
            "reviews.didPurchase     34659\n",
            "reviews.doRecommend       594\n",
            "reviews.id              34659\n",
            "reviews.numHelpful        529\n",
            "reviews.rating             33\n",
            "reviews.sourceURLs          0\n",
            "reviews.text                1\n",
            "reviews.title               6\n",
            "reviews.userCity        34660\n",
            "reviews.userProvince    34660\n",
            "reviews.username            7\n",
            "dtype: int64\n",
            "\n",
            "First few rows of the dataset:\n",
            "                     id                                               name  \\\n",
            "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "\n",
            "        asins   brand                                         categories  \\\n",
            "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "\n",
            "                                                keys manufacturer  \\\n",
            "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "\n",
            "               reviews.date     reviews.dateAdded  \\\n",
            "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "\n",
            "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
            "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "\n",
            "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
            "0        NaN                 0.0             5.0   \n",
            "1        NaN                 0.0             5.0   \n",
            "2        NaN                 0.0             5.0   \n",
            "3        NaN                 0.0             4.0   \n",
            "4        NaN                 0.0             5.0   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  This product so far has not disappointed. My c...   \n",
            "1  great for beginner or experienced person. Boug...   \n",
            "2  Inexpensive tablet for him to use and learn on...   \n",
            "3  I've had my Fire HD 8 two weeks now and I love...   \n",
            "4  I bought this for my grand daughter when she c...   \n",
            "\n",
            "                             reviews.title reviews.userCity  \\\n",
            "0                                   Kindle              NaN   \n",
            "1                                very fast              NaN   \n",
            "2  Beginner tablet for our 9 year old son.              NaN   \n",
            "3                                  Good!!!              NaN   \n",
            "4                Fantastic Tablet for kids              NaN   \n",
            "\n",
            "   reviews.userProvince  reviews.username  \n",
            "0                   NaN           Adapter  \n",
            "1                   NaN            truman  \n",
            "2                   NaN             DaveZ  \n",
            "3                   NaN            Shacks  \n",
            "4                   NaN         explore42  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3725 - loss: 1.3926 - val_accuracy: 0.6751 - val_loss: 0.8778\n",
            "Epoch 2/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5342 - loss: 1.0314 - val_accuracy: 0.6826 - val_loss: 0.7768\n",
            "Epoch 3/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6190 - loss: 0.8900 - val_accuracy: 0.6884 - val_loss: 0.7381\n",
            "Epoch 4/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6466 - loss: 0.8335 - val_accuracy: 0.6929 - val_loss: 0.7073\n",
            "Epoch 5/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6622 - loss: 0.7978 - val_accuracy: 0.6985 - val_loss: 0.6894\n",
            "Epoch 6/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6773 - loss: 0.7651 - val_accuracy: 0.7076 - val_loss: 0.6786\n",
            "Epoch 7/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.7406 - val_accuracy: 0.7075 - val_loss: 0.6711\n",
            "Epoch 8/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6901 - loss: 0.7197 - val_accuracy: 0.7107 - val_loss: 0.6637\n",
            "Epoch 9/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.7118 - val_accuracy: 0.7121 - val_loss: 0.6639\n",
            "Epoch 10/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.7044 - val_accuracy: 0.7101 - val_loss: 0.6635\n",
            "Epoch 11/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7036 - loss: 0.6890 - val_accuracy: 0.7114 - val_loss: 0.6598\n",
            "Epoch 12/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.6764 - val_accuracy: 0.7130 - val_loss: 0.6611\n",
            "Epoch 13/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7036 - loss: 0.6816 - val_accuracy: 0.7146 - val_loss: 0.6555\n",
            "Epoch 14/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 0.6679 - val_accuracy: 0.7098 - val_loss: 0.6605\n",
            "Epoch 15/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7162 - loss: 0.6604 - val_accuracy: 0.7107 - val_loss: 0.6572\n",
            "Epoch 16/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7116 - loss: 0.6606 - val_accuracy: 0.7036 - val_loss: 0.6672\n",
            "Epoch 17/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.6653 - val_accuracy: 0.7117 - val_loss: 0.6584\n",
            "Epoch 18/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7173 - loss: 0.6607 - val_accuracy: 0.7057 - val_loss: 0.6619\n",
            "Epoch 19/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.7098 - loss: 0.6688 - val_accuracy: 0.7127 - val_loss: 0.6551\n",
            "Epoch 20/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.6556 - val_accuracy: 0.7072 - val_loss: 0.6615\n",
            "Epoch 21/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.6541 - val_accuracy: 0.7095 - val_loss: 0.6631\n",
            "Epoch 22/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.6472 - val_accuracy: 0.7121 - val_loss: 0.6560\n",
            "Epoch 23/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7161 - loss: 0.6524 - val_accuracy: 0.7137 - val_loss: 0.6535\n",
            "Epoch 24/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.6383 - val_accuracy: 0.7130 - val_loss: 0.6531\n",
            "Epoch 25/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.6408 - val_accuracy: 0.7135 - val_loss: 0.6538\n",
            "Epoch 26/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7238 - loss: 0.6458 - val_accuracy: 0.7086 - val_loss: 0.6595\n",
            "Epoch 27/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.6357 - val_accuracy: 0.7118 - val_loss: 0.6550\n",
            "Epoch 28/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.6384 - val_accuracy: 0.7144 - val_loss: 0.6542\n",
            "Epoch 29/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.6388 - val_accuracy: 0.7144 - val_loss: 0.6575\n",
            "Epoch 30/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.6391 - val_accuracy: 0.7122 - val_loss: 0.6549\n",
            "Epoch 31/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.6304 - val_accuracy: 0.7130 - val_loss: 0.6538\n",
            "Epoch 32/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7273 - loss: 0.6346 - val_accuracy: 0.7157 - val_loss: 0.6561\n",
            "Epoch 33/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.6377 - val_accuracy: 0.7125 - val_loss: 0.6561\n",
            "Epoch 34/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.6386 - val_accuracy: 0.7141 - val_loss: 0.6549\n",
            "Epoch 35/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 0.6313 - val_accuracy: 0.7055 - val_loss: 0.6678\n",
            "Epoch 36/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.6337 - val_accuracy: 0.7131 - val_loss: 0.6530\n",
            "Epoch 37/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.6306 - val_accuracy: 0.7163 - val_loss: 0.6531\n",
            "Epoch 38/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.6339 - val_accuracy: 0.7141 - val_loss: 0.6574\n",
            "Epoch 39/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 0.6293 - val_accuracy: 0.7140 - val_loss: 0.6590\n",
            "Epoch 40/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.6261 - val_accuracy: 0.7104 - val_loss: 0.6616\n",
            "Epoch 41/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.6288 - val_accuracy: 0.7160 - val_loss: 0.6521\n",
            "Epoch 42/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.6265 - val_accuracy: 0.7148 - val_loss: 0.6544\n",
            "Epoch 43/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.6215 - val_accuracy: 0.7133 - val_loss: 0.6564\n",
            "Epoch 44/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.6300 - val_accuracy: 0.7151 - val_loss: 0.6550\n",
            "Epoch 45/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6197 - val_accuracy: 0.7147 - val_loss: 0.6537\n",
            "Epoch 46/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.6178 - val_accuracy: 0.7131 - val_loss: 0.6553\n",
            "Epoch 47/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.6158 - val_accuracy: 0.7143 - val_loss: 0.6538\n",
            "Epoch 48/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.6271 - val_accuracy: 0.7173 - val_loss: 0.6538\n",
            "Epoch 49/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.6137 - val_accuracy: 0.7108 - val_loss: 0.6586\n",
            "Epoch 50/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.6278 - val_accuracy: 0.7156 - val_loss: 0.6556\n",
            "Epoch 51/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.6198 - val_accuracy: 0.6972 - val_loss: 0.6818\n",
            "Epoch 52/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.6163 - val_accuracy: 0.7137 - val_loss: 0.6589\n",
            "Epoch 53/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.6216 - val_accuracy: 0.7131 - val_loss: 0.6581\n",
            "Epoch 54/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.6179 - val_accuracy: 0.7143 - val_loss: 0.6580\n",
            "Epoch 55/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.6157 - val_accuracy: 0.7128 - val_loss: 0.6720\n",
            "Epoch 56/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7355 - loss: 0.6185 - val_accuracy: 0.7128 - val_loss: 0.6598\n",
            "Epoch 57/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.6084 - val_accuracy: 0.7164 - val_loss: 0.6591\n",
            "Epoch 58/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.6071 - val_accuracy: 0.7167 - val_loss: 0.6590\n",
            "Epoch 59/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.6130 - val_accuracy: 0.7134 - val_loss: 0.6665\n",
            "Epoch 60/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.6107 - val_accuracy: 0.7135 - val_loss: 0.6645\n",
            "Epoch 61/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6070 - val_accuracy: 0.7133 - val_loss: 0.6611\n",
            "Epoch 62/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7424 - loss: 0.6072 - val_accuracy: 0.7079 - val_loss: 0.6654\n",
            "Epoch 63/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.6158 - val_accuracy: 0.7112 - val_loss: 0.6644\n",
            "Epoch 64/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.6074 - val_accuracy: 0.7098 - val_loss: 0.6625\n",
            "Epoch 65/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.6069 - val_accuracy: 0.7147 - val_loss: 0.6631\n",
            "Epoch 66/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.6034 - val_accuracy: 0.7141 - val_loss: 0.6636\n",
            "Epoch 67/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.6046 - val_accuracy: 0.7099 - val_loss: 0.6639\n",
            "Epoch 68/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.6085 - val_accuracy: 0.7135 - val_loss: 0.6603\n",
            "Epoch 69/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.6031 - val_accuracy: 0.7133 - val_loss: 0.6620\n",
            "Epoch 70/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.6004 - val_accuracy: 0.7137 - val_loss: 0.6625\n",
            "Epoch 71/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.6049 - val_accuracy: 0.7122 - val_loss: 0.6637\n",
            "Epoch 72/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.6023 - val_accuracy: 0.7137 - val_loss: 0.6624\n",
            "Epoch 73/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.5933 - val_accuracy: 0.7125 - val_loss: 0.6651\n",
            "Epoch 74/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.5975 - val_accuracy: 0.7141 - val_loss: 0.6641\n",
            "Epoch 75/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.6032 - val_accuracy: 0.7134 - val_loss: 0.6689\n",
            "Epoch 76/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5979 - val_accuracy: 0.7127 - val_loss: 0.6672\n",
            "Epoch 77/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5997 - val_accuracy: 0.7137 - val_loss: 0.6668\n",
            "Epoch 78/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.5977 - val_accuracy: 0.7164 - val_loss: 0.6637\n",
            "Epoch 79/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7473 - loss: 0.5926 - val_accuracy: 0.7141 - val_loss: 0.6681\n",
            "Epoch 80/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.5915 - val_accuracy: 0.7151 - val_loss: 0.6678\n",
            "Epoch 81/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5956 - val_accuracy: 0.7130 - val_loss: 0.6678\n",
            "Epoch 82/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7468 - loss: 0.5866 - val_accuracy: 0.7154 - val_loss: 0.6670\n",
            "Epoch 83/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5979 - val_accuracy: 0.7148 - val_loss: 0.6766\n",
            "Epoch 84/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.5932 - val_accuracy: 0.7130 - val_loss: 0.6733\n",
            "Epoch 85/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.5793 - val_accuracy: 0.7104 - val_loss: 0.6711\n",
            "Epoch 86/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.5800 - val_accuracy: 0.7150 - val_loss: 0.6710\n",
            "Epoch 87/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7507 - loss: 0.5781 - val_accuracy: 0.7101 - val_loss: 0.6722\n",
            "Epoch 88/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5966 - val_accuracy: 0.7082 - val_loss: 0.6762\n",
            "Epoch 89/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.5864 - val_accuracy: 0.7102 - val_loss: 0.6741\n",
            "Epoch 90/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7446 - loss: 0.5877 - val_accuracy: 0.7130 - val_loss: 0.6841\n",
            "Epoch 91/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.5876 - val_accuracy: 0.7154 - val_loss: 0.6746\n",
            "Epoch 92/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.5788 - val_accuracy: 0.7065 - val_loss: 0.6730\n",
            "Epoch 93/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.5787 - val_accuracy: 0.7148 - val_loss: 0.6829\n",
            "Epoch 94/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.5801 - val_accuracy: 0.7088 - val_loss: 0.6803\n",
            "Epoch 95/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7464 - loss: 0.5826 - val_accuracy: 0.7078 - val_loss: 0.6809\n",
            "Epoch 96/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7480 - loss: 0.5844 - val_accuracy: 0.7137 - val_loss: 0.6775\n",
            "Epoch 97/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.5809 - val_accuracy: 0.7086 - val_loss: 0.6773\n",
            "Epoch 98/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.5817 - val_accuracy: 0.7098 - val_loss: 0.6828\n",
            "Epoch 99/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.5781 - val_accuracy: 0.7133 - val_loss: 0.6796\n",
            "Epoch 100/100\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.5749 - val_accuracy: 0.7083 - val_loss: 0.6838\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7012 - loss: 0.6851\n",
            "Test Accuracy: 0.708345353603363\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.35      0.39       435\n",
            "           1       0.50      0.25      0.33      1756\n",
            "           2       0.76      0.91      0.83      4735\n",
            "\n",
            "    accuracy                           0.71      6926\n",
            "   macro avg       0.57      0.50      0.52      6926\n",
            "weighted avg       0.67      0.71      0.67      6926\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 151  108  176]\n",
            " [ 105  437 1214]\n",
            " [  82  335 4318]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load Data\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '1429_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Basic Data Exploration\n",
        "print(\"Basic Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Filter Relevant Columns\n",
        "df_filtered = df[['reviews.text', 'reviews.rating']]\n",
        "df_filtered = df_filtered.dropna(subset=['reviews.text', 'reviews.rating'])\n",
        "\n",
        "# Step 4: Download Necessary NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 5: Define Text Cleaning Functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered['reviews.text'].apply(clean_text)\n",
        "\n",
        "# Step 6: Additional Feature Engineering\n",
        "df_filtered['word_count'] = df_filtered['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "df_filtered['avg_word_length'] = df_filtered['cleaned_text'].apply(lambda x: sum(len(word) for word in x.split()) / len(x.split()) if x.split() else 0)\n",
        "\n",
        "# Define a function to categorize ratings into sentiment\n",
        "def categorize_rating(rating):\n",
        "    if rating in [1, 2, 3]:\n",
        "        return 'Negative'\n",
        "    elif rating == 4:\n",
        "        return 'Neutral'\n",
        "    elif rating == 5:\n",
        "        return 'Positive'\n",
        "\n",
        "df_filtered['sentiment'] = df_filtered['reviews.rating'].apply(categorize_rating)\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df_filtered['sentiment_label'] = df_filtered['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Step 7: TF-IDF Feature Engineering\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df_filtered['cleaned_text'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the DataFrame\n",
        "df_filtered = pd.concat([df_filtered.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Prepare the feature set\n",
        "X = df_filtered.drop(columns=['reviews.text', 'reviews.rating', 'sentiment', 'cleaned_text', 'sentiment_label'])\n",
        "y = df_filtered['sentiment_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Neural Network Model Training and Evaluation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "model.add(Dense(128, activation='selu', input_shape=(X_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(64, activation='selu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Third hidden layer\n",
        "model.add(Dense(32, activation='selu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer with 3 classes using softmax activation for multi-class classification\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model with an appropriate optimizer and loss function\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Evaluate the model performance\n",
        "classification_rep = classification_report(y_test, y_pred_classes)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Display results\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Save the final processed DataFrame\n",
        "df_filtered.to_csv('processed_reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm6ElovGQUT7",
        "outputId": "2c97b43a-c53d-4e43-86e4-0c8214e0469d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-7695f1ca5602>:18: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34660 entries, 0 to 34659\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    34660 non-null  object \n",
            " 1   name                  27900 non-null  object \n",
            " 2   asins                 34658 non-null  object \n",
            " 3   brand                 34660 non-null  object \n",
            " 4   categories            34660 non-null  object \n",
            " 5   keys                  34660 non-null  object \n",
            " 6   manufacturer          34660 non-null  object \n",
            " 7   reviews.date          34621 non-null  object \n",
            " 8   reviews.dateAdded     24039 non-null  object \n",
            " 9   reviews.dateSeen      34660 non-null  object \n",
            " 10  reviews.didPurchase   1 non-null      object \n",
            " 11  reviews.doRecommend   34066 non-null  object \n",
            " 12  reviews.id            1 non-null      float64\n",
            " 13  reviews.numHelpful    34131 non-null  float64\n",
            " 14  reviews.rating        34627 non-null  float64\n",
            " 15  reviews.sourceURLs    34660 non-null  object \n",
            " 16  reviews.text          34659 non-null  object \n",
            " 17  reviews.title         34654 non-null  object \n",
            " 18  reviews.userCity      0 non-null      float64\n",
            " 19  reviews.userProvince  0 non-null      float64\n",
            " 20  reviews.username      34653 non-null  object \n",
            "dtypes: float64(5), object(16)\n",
            "memory usage: 5.6+ MB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "id                          0\n",
            "name                     6760\n",
            "asins                       2\n",
            "brand                       0\n",
            "categories                  0\n",
            "keys                        0\n",
            "manufacturer                0\n",
            "reviews.date               39\n",
            "reviews.dateAdded       10621\n",
            "reviews.dateSeen            0\n",
            "reviews.didPurchase     34659\n",
            "reviews.doRecommend       594\n",
            "reviews.id              34659\n",
            "reviews.numHelpful        529\n",
            "reviews.rating             33\n",
            "reviews.sourceURLs          0\n",
            "reviews.text                1\n",
            "reviews.title               6\n",
            "reviews.userCity        34660\n",
            "reviews.userProvince    34660\n",
            "reviews.username            7\n",
            "dtype: int64\n",
            "\n",
            "First few rows of the dataset:\n",
            "                     id                                               name  \\\n",
            "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "\n",
            "        asins   brand                                         categories  \\\n",
            "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "\n",
            "                                                keys manufacturer  \\\n",
            "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "\n",
            "               reviews.date     reviews.dateAdded  \\\n",
            "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "\n",
            "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
            "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "\n",
            "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
            "0        NaN                 0.0             5.0   \n",
            "1        NaN                 0.0             5.0   \n",
            "2        NaN                 0.0             5.0   \n",
            "3        NaN                 0.0             4.0   \n",
            "4        NaN                 0.0             5.0   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  This product so far has not disappointed. My c...   \n",
            "1  great for beginner or experienced person. Boug...   \n",
            "2  Inexpensive tablet for him to use and learn on...   \n",
            "3  I've had my Fire HD 8 two weeks now and I love...   \n",
            "4  I bought this for my grand daughter when she c...   \n",
            "\n",
            "                             reviews.title reviews.userCity  \\\n",
            "0                                   Kindle              NaN   \n",
            "1                                very fast              NaN   \n",
            "2  Beginner tablet for our 9 year old son.              NaN   \n",
            "3                                  Good!!!              NaN   \n",
            "4                Fantastic Tablet for kids              NaN   \n",
            "\n",
            "   reviews.userProvince  reviews.username  \n",
            "0                   NaN           Adapter  \n",
            "1                   NaN            truman  \n",
            "2                   NaN             DaveZ  \n",
            "3                   NaN            Shacks  \n",
            "4                   NaN         explore42  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4901 - loss: 1.3340 - val_accuracy: 0.6809 - val_loss: 0.7963\n",
            "Epoch 2/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6327 - loss: 0.9686 - val_accuracy: 0.6805 - val_loss: 0.7737\n",
            "Epoch 3/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6446 - loss: 0.9054 - val_accuracy: 0.6818 - val_loss: 0.7683\n",
            "Epoch 4/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6677 - loss: 0.8484 - val_accuracy: 0.6813 - val_loss: 0.7534\n",
            "Epoch 5/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6674 - loss: 0.8277 - val_accuracy: 0.6818 - val_loss: 0.7462\n",
            "Epoch 6/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.7889 - val_accuracy: 0.6815 - val_loss: 0.7316\n",
            "Epoch 7/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6827 - loss: 0.7680 - val_accuracy: 0.6851 - val_loss: 0.7192\n",
            "Epoch 8/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.7453 - val_accuracy: 0.6923 - val_loss: 0.7065\n",
            "Epoch 9/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.7471 - val_accuracy: 0.6935 - val_loss: 0.7002\n",
            "Epoch 10/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6974 - loss: 0.7209 - val_accuracy: 0.7026 - val_loss: 0.6894\n",
            "Epoch 11/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.7086 - val_accuracy: 0.7031 - val_loss: 0.6827\n",
            "Epoch 12/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.7105 - val_accuracy: 0.7031 - val_loss: 0.6790\n",
            "Epoch 13/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: 0.6877 - val_accuracy: 0.7083 - val_loss: 0.6751\n",
            "Epoch 14/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.6852 - val_accuracy: 0.7086 - val_loss: 0.6709\n",
            "Epoch 15/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.6823 - val_accuracy: 0.7098 - val_loss: 0.6685\n",
            "Epoch 16/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.6805 - val_accuracy: 0.7099 - val_loss: 0.6688\n",
            "Epoch 17/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 0.6729 - val_accuracy: 0.7099 - val_loss: 0.6648\n",
            "Epoch 18/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.6635 - val_accuracy: 0.7099 - val_loss: 0.6634\n",
            "Epoch 19/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.6696 - val_accuracy: 0.7066 - val_loss: 0.6629\n",
            "Epoch 20/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.6681 - val_accuracy: 0.7104 - val_loss: 0.6608\n",
            "Epoch 21/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.6730 - val_accuracy: 0.7109 - val_loss: 0.6617\n",
            "Epoch 22/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7150 - loss: 0.6589 - val_accuracy: 0.7089 - val_loss: 0.6603\n",
            "Epoch 23/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.6569 - val_accuracy: 0.7096 - val_loss: 0.6589\n",
            "Epoch 24/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.6526 - val_accuracy: 0.7075 - val_loss: 0.6598\n",
            "Epoch 25/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.6510 - val_accuracy: 0.7085 - val_loss: 0.6584\n",
            "Epoch 26/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.6504 - val_accuracy: 0.7098 - val_loss: 0.6578\n",
            "Epoch 27/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.6494 - val_accuracy: 0.7083 - val_loss: 0.6580\n",
            "Epoch 28/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.6423 - val_accuracy: 0.7107 - val_loss: 0.6572\n",
            "Epoch 29/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.6444 - val_accuracy: 0.7099 - val_loss: 0.6582\n",
            "Epoch 30/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.6386 - val_accuracy: 0.7083 - val_loss: 0.6589\n",
            "Epoch 31/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.6485 - val_accuracy: 0.7088 - val_loss: 0.6572\n",
            "Epoch 32/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7247 - loss: 0.6459 - val_accuracy: 0.7104 - val_loss: 0.6588\n",
            "Epoch 33/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.6442 - val_accuracy: 0.7124 - val_loss: 0.6573\n",
            "Epoch 34/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.6413 - val_accuracy: 0.7118 - val_loss: 0.6573\n",
            "Epoch 35/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7256 - loss: 0.6401 - val_accuracy: 0.7134 - val_loss: 0.6581\n",
            "Epoch 36/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7221 - loss: 0.6499 - val_accuracy: 0.7118 - val_loss: 0.6583\n",
            "Epoch 37/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.6449 - val_accuracy: 0.7118 - val_loss: 0.6592\n",
            "Epoch 38/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.6402 - val_accuracy: 0.7141 - val_loss: 0.6590\n",
            "Epoch 39/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7282 - loss: 0.6382 - val_accuracy: 0.7114 - val_loss: 0.6590\n",
            "Epoch 40/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.6414 - val_accuracy: 0.7128 - val_loss: 0.6586\n",
            "Epoch 41/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.6281 - val_accuracy: 0.7094 - val_loss: 0.6619\n",
            "Epoch 42/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.6440 - val_accuracy: 0.7131 - val_loss: 0.6582\n",
            "Epoch 43/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.6370 - val_accuracy: 0.7108 - val_loss: 0.6584\n",
            "Epoch 44/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.6377 - val_accuracy: 0.7120 - val_loss: 0.6591\n",
            "Epoch 45/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.6311 - val_accuracy: 0.7130 - val_loss: 0.6591\n",
            "Epoch 46/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7260 - loss: 0.6348 - val_accuracy: 0.7130 - val_loss: 0.6589\n",
            "Epoch 47/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.6321 - val_accuracy: 0.7098 - val_loss: 0.6597\n",
            "Epoch 48/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.6286 - val_accuracy: 0.7135 - val_loss: 0.6593\n",
            "Epoch 49/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.6363 - val_accuracy: 0.7137 - val_loss: 0.6589\n",
            "Epoch 50/50\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.6344 - val_accuracy: 0.7135 - val_loss: 0.6588\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7062 - loss: 0.6685\n",
            "Test Accuracy: 0.713543176651001\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.28      0.36       435\n",
            "           1       0.54      0.20      0.29      1756\n",
            "           2       0.74      0.94      0.83      4735\n",
            "\n",
            "    accuracy                           0.71      6926\n",
            "   macro avg       0.59      0.48      0.49      6926\n",
            "weighted avg       0.67      0.71      0.66      6926\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 122   95  218]\n",
            " [  72  355 1329]\n",
            " [  58  212 4465]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load Data\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '1429_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Basic Data Exploration\n",
        "print(\"Basic Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Filter Relevant Columns\n",
        "df_filtered = df[['reviews.text', 'reviews.rating']]\n",
        "df_filtered = df_filtered.dropna(subset=['reviews.text', 'reviews.rating'])\n",
        "\n",
        "# Step 4: Download Necessary NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 5: Define Text Cleaning Functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered['reviews.text'].apply(clean_text)\n",
        "\n",
        "# Step 6: Additional Feature Engineering\n",
        "df_filtered['word_count'] = df_filtered['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "df_filtered['avg_word_length'] = df_filtered['cleaned_text'].apply(lambda x: sum(len(word) for word in x.split()) / len(x.split()) if x.split() else 0)\n",
        "\n",
        "# Define a function to categorize ratings into sentiment\n",
        "def categorize_rating(rating):\n",
        "    if rating in [1, 2, 3]:\n",
        "        return 'Negative'\n",
        "    elif rating == 4:\n",
        "        return 'Neutral'\n",
        "    elif rating == 5:\n",
        "        return 'Positive'\n",
        "\n",
        "df_filtered['sentiment'] = df_filtered['reviews.rating'].apply(categorize_rating)\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df_filtered['sentiment_label'] = df_filtered['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Step 7: TF-IDF Feature Engineering\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df_filtered['cleaned_text'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the DataFrame\n",
        "df_filtered = pd.concat([df_filtered.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Prepare the feature set\n",
        "X = df_filtered.drop(columns=['reviews.text', 'reviews.rating', 'sentiment', 'cleaned_text', 'sentiment_label'])\n",
        "y = df_filtered['sentiment_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Neural Network Model Training and Evaluation\n",
        "# Define a simple feedforward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='selu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='selu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Evaluate the model performance\n",
        "classification_rep = classification_report(y_test, y_pred_classes)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Display results\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Save the final processed DataFrame\n",
        "df_filtered.to_csv('processed_reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD655VeaUyrD",
        "outputId": "9b1f6f55-d405-44fe-dc74-b08fe711d3e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-31-1d109dfcf19d>:18: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34660 entries, 0 to 34659\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    34660 non-null  object \n",
            " 1   name                  27900 non-null  object \n",
            " 2   asins                 34658 non-null  object \n",
            " 3   brand                 34660 non-null  object \n",
            " 4   categories            34660 non-null  object \n",
            " 5   keys                  34660 non-null  object \n",
            " 6   manufacturer          34660 non-null  object \n",
            " 7   reviews.date          34621 non-null  object \n",
            " 8   reviews.dateAdded     24039 non-null  object \n",
            " 9   reviews.dateSeen      34660 non-null  object \n",
            " 10  reviews.didPurchase   1 non-null      object \n",
            " 11  reviews.doRecommend   34066 non-null  object \n",
            " 12  reviews.id            1 non-null      float64\n",
            " 13  reviews.numHelpful    34131 non-null  float64\n",
            " 14  reviews.rating        34627 non-null  float64\n",
            " 15  reviews.sourceURLs    34660 non-null  object \n",
            " 16  reviews.text          34659 non-null  object \n",
            " 17  reviews.title         34654 non-null  object \n",
            " 18  reviews.userCity      0 non-null      float64\n",
            " 19  reviews.userProvince  0 non-null      float64\n",
            " 20  reviews.username      34653 non-null  object \n",
            "dtypes: float64(5), object(16)\n",
            "memory usage: 5.6+ MB\n",
            "None\n",
            "\n",
            "Missing values:\n",
            "id                          0\n",
            "name                     6760\n",
            "asins                       2\n",
            "brand                       0\n",
            "categories                  0\n",
            "keys                        0\n",
            "manufacturer                0\n",
            "reviews.date               39\n",
            "reviews.dateAdded       10621\n",
            "reviews.dateSeen            0\n",
            "reviews.didPurchase     34659\n",
            "reviews.doRecommend       594\n",
            "reviews.id              34659\n",
            "reviews.numHelpful        529\n",
            "reviews.rating             33\n",
            "reviews.sourceURLs          0\n",
            "reviews.text                1\n",
            "reviews.title               6\n",
            "reviews.userCity        34660\n",
            "reviews.userProvince    34660\n",
            "reviews.username            7\n",
            "dtype: int64\n",
            "\n",
            "First few rows of the dataset:\n",
            "                     id                                               name  \\\n",
            "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
            "\n",
            "        asins   brand                                         categories  \\\n",
            "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
            "\n",
            "                                                keys manufacturer  \\\n",
            "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
            "\n",
            "               reviews.date     reviews.dateAdded  \\\n",
            "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
            "\n",
            "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
            "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
            "\n",
            "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
            "0        NaN                 0.0             5.0   \n",
            "1        NaN                 0.0             5.0   \n",
            "2        NaN                 0.0             5.0   \n",
            "3        NaN                 0.0             4.0   \n",
            "4        NaN                 0.0             5.0   \n",
            "\n",
            "                                  reviews.sourceURLs  \\\n",
            "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
            "\n",
            "                                        reviews.text  \\\n",
            "0  This product so far has not disappointed. My c...   \n",
            "1  great for beginner or experienced person. Boug...   \n",
            "2  Inexpensive tablet for him to use and learn on...   \n",
            "3  I've had my Fire HD 8 two weeks now and I love...   \n",
            "4  I bought this for my grand daughter when she c...   \n",
            "\n",
            "                             reviews.title reviews.userCity  \\\n",
            "0                                   Kindle              NaN   \n",
            "1                                very fast              NaN   \n",
            "2  Beginner tablet for our 9 year old son.              NaN   \n",
            "3                                  Good!!!              NaN   \n",
            "4                Fantastic Tablet for kids              NaN   \n",
            "\n",
            "   reviews.userProvince  reviews.username  \n",
            "0                   NaN           Adapter  \n",
            "1                   NaN            truman  \n",
            "2                   NaN             DaveZ  \n",
            "3                   NaN            Shacks  \n",
            "4                   NaN         explore42  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5364 - loss: 1.2860 - val_accuracy: 0.6837 - val_loss: 0.8045\n",
            "Epoch 2/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6218 - loss: 1.0012 - val_accuracy: 0.6837 - val_loss: 0.7805\n",
            "Epoch 3/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6457 - loss: 0.9193 - val_accuracy: 0.6837 - val_loss: 0.7664\n",
            "Epoch 4/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6555 - loss: 0.8669 - val_accuracy: 0.6837 - val_loss: 0.7567\n",
            "Epoch 5/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6686 - loss: 0.8265 - val_accuracy: 0.6837 - val_loss: 0.7439\n",
            "Epoch 6/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.8067 - val_accuracy: 0.6841 - val_loss: 0.7252\n",
            "Epoch 7/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6775 - loss: 0.7781 - val_accuracy: 0.6867 - val_loss: 0.7140\n",
            "Epoch 8/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.7565 - val_accuracy: 0.6920 - val_loss: 0.7029\n",
            "Epoch 9/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.7377 - val_accuracy: 0.6964 - val_loss: 0.6925\n",
            "Epoch 10/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7199 - val_accuracy: 0.7004 - val_loss: 0.6865\n",
            "Epoch 11/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6959 - loss: 0.7126 - val_accuracy: 0.7034 - val_loss: 0.6812\n",
            "Epoch 12/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6978 - loss: 0.7065 - val_accuracy: 0.7040 - val_loss: 0.6781\n",
            "Epoch 13/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.6891 - val_accuracy: 0.7066 - val_loss: 0.6731\n",
            "Epoch 14/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.6881 - val_accuracy: 0.7055 - val_loss: 0.6719\n",
            "Epoch 15/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.6836 - val_accuracy: 0.7059 - val_loss: 0.6679\n",
            "Epoch 16/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.6825 - val_accuracy: 0.7063 - val_loss: 0.6674\n",
            "Epoch 17/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.6733 - val_accuracy: 0.7043 - val_loss: 0.6649\n",
            "Epoch 18/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.6722 - val_accuracy: 0.7085 - val_loss: 0.6644\n",
            "Epoch 19/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.6689 - val_accuracy: 0.7083 - val_loss: 0.6620\n",
            "Epoch 20/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6566 - val_accuracy: 0.7086 - val_loss: 0.6610\n",
            "Epoch 21/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7128 - loss: 0.6674 - val_accuracy: 0.7094 - val_loss: 0.6596\n",
            "Epoch 22/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.6662 - val_accuracy: 0.7079 - val_loss: 0.6621\n",
            "Epoch 23/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.6600 - val_accuracy: 0.7107 - val_loss: 0.6591\n",
            "Epoch 24/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.6563 - val_accuracy: 0.7088 - val_loss: 0.6584\n",
            "Epoch 25/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.6523 - val_accuracy: 0.7107 - val_loss: 0.6585\n",
            "Epoch 26/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.6517 - val_accuracy: 0.7095 - val_loss: 0.6581\n",
            "Epoch 27/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.6492 - val_accuracy: 0.7053 - val_loss: 0.6628\n",
            "Epoch 28/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.6513 - val_accuracy: 0.7108 - val_loss: 0.6581\n",
            "Epoch 29/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.6558 - val_accuracy: 0.7078 - val_loss: 0.6584\n",
            "Epoch 30/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.6455 - val_accuracy: 0.7102 - val_loss: 0.6576\n",
            "Epoch 31/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.6439 - val_accuracy: 0.7104 - val_loss: 0.6573\n",
            "Epoch 32/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.6488 - val_accuracy: 0.7056 - val_loss: 0.6620\n",
            "Epoch 33/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7214 - loss: 0.6483 - val_accuracy: 0.7098 - val_loss: 0.6590\n",
            "Epoch 34/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.6386 - val_accuracy: 0.7108 - val_loss: 0.6573\n",
            "Epoch 35/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7245 - loss: 0.6420 - val_accuracy: 0.7099 - val_loss: 0.6583\n",
            "Epoch 36/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.6376 - val_accuracy: 0.7096 - val_loss: 0.6582\n",
            "Epoch 37/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.6403 - val_accuracy: 0.7098 - val_loss: 0.6581\n",
            "Epoch 38/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.6423 - val_accuracy: 0.7108 - val_loss: 0.6569\n",
            "Epoch 39/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.6506 - val_accuracy: 0.7092 - val_loss: 0.6577\n",
            "Epoch 40/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.6399 - val_accuracy: 0.7112 - val_loss: 0.6573\n",
            "Epoch 41/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.6382 - val_accuracy: 0.7112 - val_loss: 0.6591\n",
            "Epoch 42/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.6396 - val_accuracy: 0.7105 - val_loss: 0.6585\n",
            "Epoch 43/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.6373 - val_accuracy: 0.7108 - val_loss: 0.6591\n",
            "Epoch 44/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6393 - val_accuracy: 0.7108 - val_loss: 0.6588\n",
            "Epoch 45/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.6379 - val_accuracy: 0.7124 - val_loss: 0.6573\n",
            "Epoch 46/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.6323 - val_accuracy: 0.7114 - val_loss: 0.6586\n",
            "Epoch 47/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.6376 - val_accuracy: 0.7121 - val_loss: 0.6589\n",
            "Epoch 48/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.6369 - val_accuracy: 0.7098 - val_loss: 0.6588\n",
            "Epoch 49/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.6359 - val_accuracy: 0.7130 - val_loss: 0.6582\n",
            "Epoch 50/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.6370 - val_accuracy: 0.7135 - val_loss: 0.6579\n",
            "Epoch 51/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.6356 - val_accuracy: 0.7128 - val_loss: 0.6584\n",
            "Epoch 52/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.6370 - val_accuracy: 0.7134 - val_loss: 0.6611\n",
            "Epoch 53/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.6377 - val_accuracy: 0.7127 - val_loss: 0.6588\n",
            "Epoch 54/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.6353 - val_accuracy: 0.7125 - val_loss: 0.6598\n",
            "Epoch 55/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.6301 - val_accuracy: 0.7133 - val_loss: 0.6581\n",
            "Epoch 56/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.6376 - val_accuracy: 0.7104 - val_loss: 0.6588\n",
            "Epoch 57/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.6326 - val_accuracy: 0.7114 - val_loss: 0.6598\n",
            "Epoch 58/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.6348 - val_accuracy: 0.7140 - val_loss: 0.6588\n",
            "Epoch 59/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7329 - loss: 0.6347 - val_accuracy: 0.7118 - val_loss: 0.6608\n",
            "Epoch 60/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.6303 - val_accuracy: 0.7111 - val_loss: 0.6607\n",
            "Epoch 61/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.6378 - val_accuracy: 0.7120 - val_loss: 0.6596\n",
            "Epoch 62/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.6346 - val_accuracy: 0.7117 - val_loss: 0.6594\n",
            "Epoch 63/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.6264 - val_accuracy: 0.7115 - val_loss: 0.6599\n",
            "Epoch 64/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.6387 - val_accuracy: 0.7104 - val_loss: 0.6605\n",
            "Epoch 65/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.6326 - val_accuracy: 0.7099 - val_loss: 0.6623\n",
            "Epoch 66/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.6390 - val_accuracy: 0.7114 - val_loss: 0.6610\n",
            "Epoch 67/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.6321 - val_accuracy: 0.7131 - val_loss: 0.6599\n",
            "Epoch 68/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.6291 - val_accuracy: 0.7118 - val_loss: 0.6600\n",
            "Epoch 69/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.6323 - val_accuracy: 0.7130 - val_loss: 0.6590\n",
            "Epoch 70/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.6384 - val_accuracy: 0.7118 - val_loss: 0.6601\n",
            "Epoch 71/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.6258 - val_accuracy: 0.7120 - val_loss: 0.6627\n",
            "Epoch 72/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6227 - val_accuracy: 0.7128 - val_loss: 0.6594\n",
            "Epoch 73/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.6264 - val_accuracy: 0.7131 - val_loss: 0.6597\n",
            "Epoch 74/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.6343 - val_accuracy: 0.7122 - val_loss: 0.6600\n",
            "Epoch 75/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7299 - loss: 0.6307 - val_accuracy: 0.7141 - val_loss: 0.6600\n",
            "Epoch 76/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.6308 - val_accuracy: 0.7128 - val_loss: 0.6600\n",
            "Epoch 77/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.6351 - val_accuracy: 0.7131 - val_loss: 0.6592\n",
            "Epoch 78/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.6321 - val_accuracy: 0.7133 - val_loss: 0.6604\n",
            "Epoch 79/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.6264 - val_accuracy: 0.7134 - val_loss: 0.6607\n",
            "Epoch 80/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.6250 - val_accuracy: 0.7134 - val_loss: 0.6597\n",
            "Epoch 81/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.6327 - val_accuracy: 0.7143 - val_loss: 0.6619\n",
            "Epoch 82/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.6283 - val_accuracy: 0.7140 - val_loss: 0.6598\n",
            "Epoch 83/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.6327 - val_accuracy: 0.7105 - val_loss: 0.6603\n",
            "Epoch 84/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.6252 - val_accuracy: 0.7133 - val_loss: 0.6591\n",
            "Epoch 85/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.6277 - val_accuracy: 0.7115 - val_loss: 0.6596\n",
            "Epoch 86/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.6350 - val_accuracy: 0.7141 - val_loss: 0.6597\n",
            "Epoch 87/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.6246 - val_accuracy: 0.7127 - val_loss: 0.6599\n",
            "Epoch 88/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.6287 - val_accuracy: 0.7134 - val_loss: 0.6606\n",
            "Epoch 89/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.6245 - val_accuracy: 0.7133 - val_loss: 0.6602\n",
            "Epoch 90/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.6300 - val_accuracy: 0.7124 - val_loss: 0.6595\n",
            "Epoch 91/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.6351 - val_accuracy: 0.7133 - val_loss: 0.6603\n",
            "Epoch 92/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.6291 - val_accuracy: 0.7138 - val_loss: 0.6604\n",
            "Epoch 93/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.6335 - val_accuracy: 0.7122 - val_loss: 0.6614\n",
            "Epoch 94/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.6363 - val_accuracy: 0.7127 - val_loss: 0.6605\n",
            "Epoch 95/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 0.6291 - val_accuracy: 0.7115 - val_loss: 0.6605\n",
            "Epoch 96/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.6247 - val_accuracy: 0.7124 - val_loss: 0.6609\n",
            "Epoch 97/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.6279 - val_accuracy: 0.7115 - val_loss: 0.6606\n",
            "Epoch 98/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.6364 - val_accuracy: 0.7137 - val_loss: 0.6602\n",
            "Epoch 99/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.6249 - val_accuracy: 0.7111 - val_loss: 0.6609\n",
            "Epoch 100/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.6248 - val_accuracy: 0.7118 - val_loss: 0.6615\n",
            "Epoch 101/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.6263 - val_accuracy: 0.7117 - val_loss: 0.6608\n",
            "Epoch 102/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.6248 - val_accuracy: 0.7083 - val_loss: 0.6635\n",
            "Epoch 103/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.6295 - val_accuracy: 0.7151 - val_loss: 0.6609\n",
            "Epoch 104/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.6327 - val_accuracy: 0.7124 - val_loss: 0.6596\n",
            "Epoch 105/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.6311 - val_accuracy: 0.7135 - val_loss: 0.6609\n",
            "Epoch 106/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.6277 - val_accuracy: 0.7125 - val_loss: 0.6601\n",
            "Epoch 107/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.6272 - val_accuracy: 0.7127 - val_loss: 0.6609\n",
            "Epoch 108/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.6255 - val_accuracy: 0.7141 - val_loss: 0.6609\n",
            "Epoch 109/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.6281 - val_accuracy: 0.7105 - val_loss: 0.6613\n",
            "Epoch 110/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6207 - val_accuracy: 0.7128 - val_loss: 0.6601\n",
            "Epoch 111/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7310 - loss: 0.6293 - val_accuracy: 0.7137 - val_loss: 0.6604\n",
            "Epoch 112/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.6316 - val_accuracy: 0.7088 - val_loss: 0.6635\n",
            "Epoch 113/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.6356 - val_accuracy: 0.7133 - val_loss: 0.6601\n",
            "Epoch 114/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6259 - val_accuracy: 0.7134 - val_loss: 0.6608\n",
            "Epoch 115/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7328 - loss: 0.6242 - val_accuracy: 0.7133 - val_loss: 0.6606\n",
            "Epoch 116/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.6325 - val_accuracy: 0.7151 - val_loss: 0.6620\n",
            "Epoch 117/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.6425 - val_accuracy: 0.7143 - val_loss: 0.6611\n",
            "Epoch 118/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.6188 - val_accuracy: 0.7105 - val_loss: 0.6609\n",
            "Epoch 119/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.6296 - val_accuracy: 0.7135 - val_loss: 0.6603\n",
            "Epoch 120/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6259 - val_accuracy: 0.7156 - val_loss: 0.6608\n",
            "Epoch 121/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.6215 - val_accuracy: 0.7124 - val_loss: 0.6604\n",
            "Epoch 122/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.6322 - val_accuracy: 0.7131 - val_loss: 0.6605\n",
            "Epoch 123/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.6336 - val_accuracy: 0.7124 - val_loss: 0.6605\n",
            "Epoch 124/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.6264 - val_accuracy: 0.7133 - val_loss: 0.6626\n",
            "Epoch 125/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.6284 - val_accuracy: 0.7135 - val_loss: 0.6613\n",
            "Epoch 126/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.6256 - val_accuracy: 0.7117 - val_loss: 0.6613\n",
            "Epoch 127/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.6261 - val_accuracy: 0.7131 - val_loss: 0.6604\n",
            "Epoch 128/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.6215 - val_accuracy: 0.7137 - val_loss: 0.6605\n",
            "Epoch 129/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.6279 - val_accuracy: 0.7138 - val_loss: 0.6611\n",
            "Epoch 130/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.6236 - val_accuracy: 0.7156 - val_loss: 0.6615\n",
            "Epoch 131/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.6336 - val_accuracy: 0.7099 - val_loss: 0.6611\n",
            "Epoch 132/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7313 - loss: 0.6319 - val_accuracy: 0.7146 - val_loss: 0.6605\n",
            "Epoch 133/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.6252 - val_accuracy: 0.7127 - val_loss: 0.6613\n",
            "Epoch 134/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.6324 - val_accuracy: 0.7146 - val_loss: 0.6605\n",
            "Epoch 135/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6280 - val_accuracy: 0.7153 - val_loss: 0.6607\n",
            "Epoch 136/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.6190 - val_accuracy: 0.7124 - val_loss: 0.6627\n",
            "Epoch 137/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.6304 - val_accuracy: 0.7124 - val_loss: 0.6604\n",
            "Epoch 138/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.6241 - val_accuracy: 0.7137 - val_loss: 0.6604\n",
            "Epoch 139/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.6365 - val_accuracy: 0.7144 - val_loss: 0.6603\n",
            "Epoch 140/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.6283 - val_accuracy: 0.7098 - val_loss: 0.6621\n",
            "Epoch 141/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.6284 - val_accuracy: 0.7133 - val_loss: 0.6601\n",
            "Epoch 142/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.6217 - val_accuracy: 0.7135 - val_loss: 0.6606\n",
            "Epoch 143/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.6253 - val_accuracy: 0.7150 - val_loss: 0.6606\n",
            "Epoch 144/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.6246 - val_accuracy: 0.7133 - val_loss: 0.6600\n",
            "Epoch 145/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.6215 - val_accuracy: 0.7122 - val_loss: 0.6601\n",
            "Epoch 146/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.6343 - val_accuracy: 0.7134 - val_loss: 0.6598\n",
            "Epoch 147/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.6269 - val_accuracy: 0.7147 - val_loss: 0.6611\n",
            "Epoch 148/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7277 - loss: 0.6324 - val_accuracy: 0.7115 - val_loss: 0.6612\n",
            "Epoch 149/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6276 - val_accuracy: 0.7111 - val_loss: 0.6621\n",
            "Epoch 150/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6256 - val_accuracy: 0.7137 - val_loss: 0.6610\n",
            "Epoch 151/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.6246 - val_accuracy: 0.7157 - val_loss: 0.6603\n",
            "Epoch 152/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.6189 - val_accuracy: 0.7146 - val_loss: 0.6607\n",
            "Epoch 153/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.6290 - val_accuracy: 0.7133 - val_loss: 0.6609\n",
            "Epoch 154/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.6259 - val_accuracy: 0.7144 - val_loss: 0.6617\n",
            "Epoch 155/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.6243 - val_accuracy: 0.7140 - val_loss: 0.6603\n",
            "Epoch 156/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.6299 - val_accuracy: 0.7135 - val_loss: 0.6609\n",
            "Epoch 157/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.6254 - val_accuracy: 0.7131 - val_loss: 0.6630\n",
            "Epoch 158/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6246 - val_accuracy: 0.7124 - val_loss: 0.6610\n",
            "Epoch 159/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.6272 - val_accuracy: 0.7130 - val_loss: 0.6619\n",
            "Epoch 160/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.6252 - val_accuracy: 0.7143 - val_loss: 0.6600\n",
            "Epoch 161/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.6161 - val_accuracy: 0.7141 - val_loss: 0.6606\n",
            "Epoch 162/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.6232 - val_accuracy: 0.7138 - val_loss: 0.6619\n",
            "Epoch 163/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.6265 - val_accuracy: 0.7130 - val_loss: 0.6611\n",
            "Epoch 164/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.6239 - val_accuracy: 0.7117 - val_loss: 0.6617\n",
            "Epoch 165/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.6285 - val_accuracy: 0.7140 - val_loss: 0.6622\n",
            "Epoch 166/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.6194 - val_accuracy: 0.7124 - val_loss: 0.6608\n",
            "Epoch 167/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.6256 - val_accuracy: 0.7140 - val_loss: 0.6603\n",
            "Epoch 168/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.6211 - val_accuracy: 0.7140 - val_loss: 0.6627\n",
            "Epoch 169/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7322 - loss: 0.6242 - val_accuracy: 0.7150 - val_loss: 0.6613\n",
            "Epoch 170/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.6177 - val_accuracy: 0.7137 - val_loss: 0.6615\n",
            "Epoch 171/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.6217 - val_accuracy: 0.7146 - val_loss: 0.6614\n",
            "Epoch 172/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.6162 - val_accuracy: 0.7143 - val_loss: 0.6611\n",
            "Epoch 173/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.6211 - val_accuracy: 0.7146 - val_loss: 0.6604\n",
            "Epoch 174/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.6225 - val_accuracy: 0.7125 - val_loss: 0.6617\n",
            "Epoch 175/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.6201 - val_accuracy: 0.7146 - val_loss: 0.6609\n",
            "Epoch 176/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7346 - loss: 0.6278 - val_accuracy: 0.7133 - val_loss: 0.6614\n",
            "Epoch 177/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.6165 - val_accuracy: 0.7150 - val_loss: 0.6607\n",
            "Epoch 178/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.6282 - val_accuracy: 0.7150 - val_loss: 0.6604\n",
            "Epoch 179/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.6226 - val_accuracy: 0.7130 - val_loss: 0.6607\n",
            "Epoch 180/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.6233 - val_accuracy: 0.7122 - val_loss: 0.6620\n",
            "Epoch 181/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.6217 - val_accuracy: 0.7127 - val_loss: 0.6619\n",
            "Epoch 182/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7321 - loss: 0.6297 - val_accuracy: 0.7137 - val_loss: 0.6622\n",
            "Epoch 183/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.6254 - val_accuracy: 0.7117 - val_loss: 0.6649\n",
            "Epoch 184/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.6137 - val_accuracy: 0.7140 - val_loss: 0.6614\n",
            "Epoch 185/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.6266 - val_accuracy: 0.7121 - val_loss: 0.6608\n",
            "Epoch 186/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.6120 - val_accuracy: 0.7157 - val_loss: 0.6622\n",
            "Epoch 187/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.6264 - val_accuracy: 0.7130 - val_loss: 0.6609\n",
            "Epoch 188/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.6206 - val_accuracy: 0.7153 - val_loss: 0.6610\n",
            "Epoch 189/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.6198 - val_accuracy: 0.7140 - val_loss: 0.6611\n",
            "Epoch 190/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.6238 - val_accuracy: 0.7140 - val_loss: 0.6627\n",
            "Epoch 191/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.6244 - val_accuracy: 0.7138 - val_loss: 0.6622\n",
            "Epoch 192/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.6143 - val_accuracy: 0.7147 - val_loss: 0.6609\n",
            "Epoch 193/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.6160 - val_accuracy: 0.7133 - val_loss: 0.6605\n",
            "Epoch 194/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.6236 - val_accuracy: 0.7102 - val_loss: 0.6667\n",
            "Epoch 195/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.6262 - val_accuracy: 0.7135 - val_loss: 0.6625\n",
            "Epoch 196/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.6210 - val_accuracy: 0.7135 - val_loss: 0.6607\n",
            "Epoch 197/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.6205 - val_accuracy: 0.7141 - val_loss: 0.6616\n",
            "Epoch 198/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.6186 - val_accuracy: 0.7122 - val_loss: 0.6614\n",
            "Epoch 199/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.6243 - val_accuracy: 0.7122 - val_loss: 0.6625\n",
            "Epoch 200/200\n",
            "\u001b[1m866/866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.6187 - val_accuracy: 0.7138 - val_loss: 0.6610\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7051 - loss: 0.6691\n",
            "Test Accuracy: 0.7138319611549377\n",
            "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.28      0.35       435\n",
            "           1       0.53      0.22      0.31      1756\n",
            "           2       0.75      0.94      0.83      4735\n",
            "\n",
            "    accuracy                           0.71      6926\n",
            "   macro avg       0.58      0.48      0.50      6926\n",
            "weighted avg       0.67      0.71      0.67      6926\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 120  102  213]\n",
            " [  72  383 1301]\n",
            " [  61  233 4441]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries and Load Data\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '1429_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Basic Data Exploration\n",
        "print(\"Basic Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Filter Relevant Columns\n",
        "df_filtered = df[['reviews.text', 'reviews.rating']]\n",
        "df_filtered = df_filtered.dropna(subset=['reviews.text', 'reviews.rating'])\n",
        "\n",
        "# Step 4: Download Necessary NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 5: Define Text Cleaning Functions\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df_filtered['cleaned_text'] = df_filtered['reviews.text'].apply(clean_text)\n",
        "\n",
        "# Step 6: Additional Feature Engineering\n",
        "df_filtered['word_count'] = df_filtered['cleaned_text'].apply(lambda x: len(x.split()))\n",
        "df_filtered['avg_word_length'] = df_filtered['cleaned_text'].apply(lambda x: sum(len(word) for word in x.split()) / len(x.split()) if x.split() else 0)\n",
        "\n",
        "# Define a function to categorize ratings into sentiment\n",
        "def categorize_rating(rating):\n",
        "    if rating in [1, 2, 3]:\n",
        "        return 'Negative'\n",
        "    elif rating == 4:\n",
        "        return 'Neutral'\n",
        "    elif rating == 5:\n",
        "        return 'Positive'\n",
        "\n",
        "df_filtered['sentiment'] = df_filtered['reviews.rating'].apply(categorize_rating)\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df_filtered['sentiment_label'] = df_filtered['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
        "\n",
        "# Step 7: TF-IDF Feature Engineering\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf.fit_transform(df_filtered['cleaned_text'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Concatenate TF-IDF features with the DataFrame\n",
        "df_filtered = pd.concat([df_filtered.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Prepare the feature set\n",
        "X = df_filtered.drop(columns=['reviews.text', 'reviews.rating', 'sentiment', 'cleaned_text', 'sentiment_label'])\n",
        "y = df_filtered['sentiment_label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 8: Neural Network Model Training and Evaluation\n",
        "# Define a simple feedforward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='selu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='selu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Evaluate the model performance\n",
        "classification_rep = classification_report(y_test, y_pred_classes)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Display results\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Save the final processed DataFrame\n",
        "df_filtered.to_csv('processed_reviews.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
