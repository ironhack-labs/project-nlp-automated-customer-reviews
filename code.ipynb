{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d69dedc-05e4-4669-87ef-99997a6fbd39",
   "metadata": {},
   "source": [
    "# **Project NLP | Automated Customers Reviews**\n",
    "\n",
    "This business case outlines the development of an NLP model to automate the processing of \n",
    "customer feedback for a retail company. \n",
    "\n",
    "Its goal is to evaluate how a traditional ML solutions (NaiveBayes, SVM, RandomForest, etc) \n",
    "compares against a Deep Learning solution (e.g, a Transformer from HuggingFace) when trying to \n",
    "analyse a user review, in terms of its score (positive, negative or neutral).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549aea58-162c-40ee-928e-912bf1078cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sylviaperez-\n",
      "[nltk_data]     montero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/sylviaperez-\n",
      "[nltk_data]     montero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sylviaperez-\n",
      "[nltk_data]     montero/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traditional Models (Naive Bayes, Logistic Regression, Random Forest)\n",
    "# Please note that the deep learning model is executed with a separate script (code_distilBERT.ipynb),\n",
    "# which has also been submitted in this project's folder\n",
    "\n",
    "# Imports the necessary Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "# Makes sure the required NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf0b638-21c0-4680-9850-62bb38ad062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id   brand  \\\n",
      "0  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "1  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "2  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "3  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "4  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "\n",
      "                                                keys manufacturer  \\\n",
      "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "\n",
      "  reviews.doRecommend  reviews.numHelpful  reviews.rating  \\\n",
      "0                True                 0.0             5.0   \n",
      "1                True                 0.0             5.0   \n",
      "2                True                 0.0             5.0   \n",
      "3                True                 0.0             4.0   \n",
      "4                True                 0.0             5.0   \n",
      "\n",
      "                                        reviews.text  \\\n",
      "0  This product so far has not disappointed. My c...   \n",
      "1  great for beginner or experienced person. Boug...   \n",
      "2  Inexpensive tablet for him to use and learn on...   \n",
      "3  I've had my Fire HD 8 two weeks now and I love...   \n",
      "4  I bought this for my grand daughter when she c...   \n",
      "\n",
      "                             reviews.title reviews.username  \n",
      "0                                   Kindle          Adapter  \n",
      "1                                very fast           truman  \n",
      "2  Beginner tablet for our 9 year old son.            DaveZ  \n",
      "3                                  Good!!!           Shacks  \n",
      "4                Fantastic Tablet for kids        explore42  \n"
     ]
    }
   ],
   "source": [
    "# Loads the dataset (and initial save checkpoint)\n",
    "df = pd.read_csv(\"/Users/sylviaperez-montero/Desktop/Project/Amazon Data.csv\", low_memory=False)\n",
    "pickle.dump(df, open(\"dataset.pkl\", \"wb\"))\n",
    "\n",
    "# Drops the unnecessary columns and saves the cleaned dataset\n",
    "columns_to_drop = [\n",
    "    'asins', 'reviews.date', 'reviews.dateAdded', 'reviews.dateSeen', \n",
    "    'reviews.id', 'reviews.didPurchase', 'name',\n",
    "    'reviews.userCity', 'reviews.userProvince', 'reviews.sourceURLs'\n",
    "]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "pickle.dump(df, open(\"cleaned_dataset.pkl\", \"wb\"))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604b920b-be33-472e-bac8-43e1eb7ba270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id   brand  \\\n",
      "0  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "1  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "2  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "3  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "4  AVqkIhwDv8e3D1O-lebb  Amazon   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
      "\n",
      "                                                keys manufacturer  \\\n",
      "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
      "\n",
      "  reviews.doRecommend  reviews.numHelpful  reviews.rating  \\\n",
      "0                True                 0.0             5.0   \n",
      "1                True                 0.0             5.0   \n",
      "2                True                 0.0             5.0   \n",
      "3                True                 0.0             4.0   \n",
      "4                True                 0.0             5.0   \n",
      "\n",
      "                                        reviews.text  \\\n",
      "0  This product so far has not disappointed. My c...   \n",
      "1  great for beginner or experienced person. Boug...   \n",
      "2  Inexpensive tablet for him to use and learn on...   \n",
      "3  I've had my Fire HD 8 two weeks now and I love...   \n",
      "4  I bought this for my grand daughter when she c...   \n",
      "\n",
      "                             reviews.title reviews.username  \\\n",
      "0                                   Kindle          Adapter   \n",
      "1                                very fast           truman   \n",
      "2  Beginner tablet for our 9 year old son.            DaveZ   \n",
      "3                                  Good!!!           Shacks   \n",
      "4                Fantastic Tablet for kids        explore42   \n",
      "\n",
      "                                cleaned_reviews_text  \\\n",
      "0  product far disappointed child love use like a...   \n",
      "1  great beginner experienced person bought gift ...   \n",
      "2  inexpensive tablet use learn step nabi thrille...   \n",
      "3  ive fire hd two week love tablet great valuewe...   \n",
      "4  bought grand daughter come visit set user ente...   \n",
      "\n",
      "          cleaned_reviews_title  \n",
      "0                        kindle  \n",
      "1                          fast  \n",
      "2  beginner tablet year old son  \n",
      "3                          good  \n",
      "4          fantastic tablet kid  \n"
     ]
    }
   ],
   "source": [
    "# Defines a text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Applies text preprocessing (and save checkpoint)\n",
    "if 'reviews.text' in df.columns:\n",
    "    df[\"cleaned_reviews_text\"] = df[\"reviews.text\"].apply(preprocess_text)\n",
    "if 'reviews.title' in df.columns:\n",
    "    df[\"cleaned_reviews_title\"] = df[\"reviews.title\"].apply(preprocess_text)\n",
    "pickle.dump(df, open(\"preprocessed_dataset.pkl\", \"wb\"))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb4e0ff-327e-4102-8802-4aacbad79ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20350    kindle loved screen broke bought replacement i...\n",
      "10527    fire decent tablet mostly us amazon store limi...\n",
      "7132     wanted inexpensive tablet would allow surf web...\n",
      "32227    great response quick navigation device make pl...\n",
      "24204    got son birthday gift low tech mom im still le...\n",
      "Name: cleaned_reviews_text, dtype: object\n",
      "20350    5.0\n",
      "10527    4.0\n",
      "7132     4.0\n",
      "32227    5.0\n",
      "24204    4.0\n",
      "Name: reviews.rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drops rows with missing target values (and save checkpoint)\n",
    "df = df.dropna(subset=['reviews.rating', 'cleaned_reviews_text'])\n",
    "pickle.dump(df, open(\"final_dataset.pkl\", \"wb\"))\n",
    "\n",
    "# Splits data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"cleaned_reviews_text\"], df[\"reviews.rating\"], test_size=0.2, random_state=42\n",
    ")\n",
    "pickle.dump((X_train, X_test, y_train, y_test), open(\"train_test_split.pkl\", \"wb\"))\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "# Vectorization using TF-IDF and CountVectorizer\n",
    "# note: the parameters here were iterated several times to see if performance was optimized\n",
    "# For example, smooth_idf=False and sublinear_tf=True to increase the difference between TF-IDF and Count\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 3),\n",
    "    sublinear_tf=True,  # Scales term frequencies logarithmically\n",
    "    smooth_idf=False,  # Prevents reducing IDF weighting for common words\n",
    "    min_df=2  # removes words that appear in only 1 document, thus reducing noise\n",
    ")\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=5000, stop_words=\"english\", ngram_range=(1, 2))\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "pickle.dump((tfidf_vectorizer, count_vectorizer, X_train_tfidf, X_test_tfidf, X_train_count, X_test_count), open(\"vectorized_data.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80837da0-dfb8-4629-b2ba-2903a1c70470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Model Training\n",
    "models = {\n",
    "    \"Naive Bayes (TF-IDF)\": MultinomialNB(),\n",
    "    \"Naive Bayes (Count)\": MultinomialNB(),\n",
    "    \"Logistic Regression (TF-IDF)\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"Logistic Regression (Count)\": LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if \"tfidf\" in name.lower():\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "    else:\n",
    "        model.fit(X_train_count, y_train)\n",
    "        y_pred = model.predict(X_test_count)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Classification Report\": classification_report(y_test, y_pred),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    pickle.dump(model, open(f\"{name.replace(' ', '_').replace('(', '').replace(')', '')}.pkl\", \"wb\"))\n",
    "pickle.dump(results, open(\"model_results.pkl\", \"wb\"))\n",
    "\n",
    "# Loads the optimized results only if the file exists\n",
    "if os.path.exists(\"optimized_model_results.pkl\"):\n",
    "    optimized_results = pickle.load(open(\"optimized_model_results.pkl\", \"rb\"))\n",
    "else:\n",
    "    optimized_results = {}\n",
    "\n",
    "# Gets the common models for comparison\n",
    "common_models = list(set(results.keys()).intersection(set(optimized_results.keys())))\n",
    "common_models.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8860fa-cf89-48d5-83bc-38f8671dc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further optimization begins here - handling imbalance\n",
    "smote = SMOTE(sampling_strategy={1: 324, 2: 324, 3: 1197}, random_state=42)\n",
    "X_train_tfidf_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "X_train_count_resampled, y_train_resampled = smote.fit_resample(X_train_count, y_train)\n",
    "pickle.dump((X_train_tfidf_resampled, X_train_count_resampled, y_train_resampled), open(\"balanced_data.pkl\", \"wb\"))\n",
    "\n",
    "# Optimized Model Training\n",
    "models_optimized = {\n",
    "    \"Naive Bayes (TF-IDF)\": MultinomialNB(),\n",
    "    \"Naive Bayes (Count)\": MultinomialNB(),\n",
    "    \"Logistic Regression (TF-IDF)\": LogisticRegression(class_weight=\"balanced\", max_iter=1000),\n",
    "    \"Logistic Regression (Count)\": LogisticRegression(class_weight=\"balanced\", max_iter=1000),\n",
    "    \"Random Forest (TF-IDF)\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\"),\n",
    "    \"Random Forest (Count)\": RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "optimized_results = {}\n",
    "\n",
    "for name, model in models_optimized.items():\n",
    "    if \"tfidf\" in name.lower():\n",
    "        model.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "    else:\n",
    "        model.fit(X_train_count_resampled, y_train_resampled)\n",
    "        y_pred = model.predict(X_test_count)\n",
    "    \n",
    "    optimized_results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Classification Report\": classification_report(y_test, y_pred),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    pickle.dump(model, open(f\"optimized_{name.replace(' ', '_').replace('(', '').replace(')', '')}.pkl\", \"wb\"))\n",
    "pickle.dump(optimized_results, open(\"optimized_model_results.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58952683-c0a6-4b8d-bae6-141f61253aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": common_models,\n",
    "    \"Initial Accuracy\": [results[m][\"Accuracy\"] for m in common_models],\n",
    "    \"Optimized Accuracy\": [optimized_results[m][\"Accuracy\"] for m in common_models]\n",
    "})\n",
    "print(\"\\nComparison of Initial and Optimized Models:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Displays the Random Forest model results\n",
    "rf_models = [m for m in optimized_results.keys() if \"Random Forest\" in m]\n",
    "rf_comparison_df = pd.DataFrame({\n",
    "    \"Model\": rf_models,\n",
    "    \"Optimized Accuracy\": [optimized_results[m][\"Accuracy\"] for m in rf_models]\n",
    "})\n",
    "print(\"\\nRandom Forest Model Performance:\")\n",
    "print(rf_comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf6ea8-3acd-4ee8-91f2-a5b57b286c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks to see how closely related are TF-IDF and count\n",
    "import numpy as np\n",
    "\n",
    "# Compare the sum of feature weights in both vectorized forms\n",
    "tfidf_sum = np.sum(X_train_tfidf.toarray(), axis=1)\n",
    "count_sum = np.sum(X_train_count.toarray(), axis=1)\n",
    "\n",
    "# Compute correlation\n",
    "correlation = np.corrcoef(tfidf_sum, count_sum)[0, 1]\n",
    "\n",
    "print(f\"Correlation between TF-IDF and Count features: {correlation}\")\n",
    "print(df.columns.tolist())  # üîç Debug: See available columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4bb2ff-1c58-485c-8793-4bfa51f848ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks in which ways, if any, they are similar or different\n",
    "tfidf_top_words = tfidf_vectorizer.get_feature_names_out()[:10]\n",
    "count_top_words = count_vectorizer.get_feature_names_out()[:10]\n",
    "\n",
    "print(\"TF-IDF Top Words:\", tfidf_top_words)\n",
    "print(\"CountVectorizer Top Words:\", count_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 (TensorFlow)",
   "language": "python",
   "name": "pyenv_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
